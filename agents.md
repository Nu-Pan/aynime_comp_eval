# agents.md

## 目的
Discordへ大量投下するアニメ静止画を、見た目の破綻を抑えつつ最小サイズに寄せるためのWebP圧縮パラメータ探索パイプラインを作るニャン。  
評価は「Discord上で縮小表示される見え方」を主戦場にして、WebPの `quality` をスイープして Pareto（サイズ vs 画質）の“膝”を狙うニャン。

## スコープ
- 入力：既存PNG（基本RGB、場合によりRGBA）ニャン。
- 出力：WebP（Pillowでエンコード）＋評価結果CSV/Parquet＋散布図（matplotlib）ニャン。
- 評価指標：主に **MS-SSIM（輝度Y）**、補助で **GMSD**、監視でPSNR（任意）ニャン。
- 評価解像度：縮小表示（ネイティブ表示）を想定した **targetA（想定：1280x720 (HD) の枠に収まるようリサイズ）** のみを使うニャン。

## 非スコープ
- Discordクライアントやサーバ側の帯域制御の再現・測定はしないニャン。
- 画質指標を「唯一の真理」にせず、最終判断は散布図とサンプル目視で決めるニャン。
- “綺麗な保存版PNG”の代替は狙わないニャン（あくまでDiscord用の軽量版）ニャン。

## 方針（重要）
1. **評価は縮小後**に行うニャン（Discordの体験に寄せるニャン）。
2. まず **縮小→WebP** を基本とし、後段で `quality` を詰めるニャン。
3. WebPは **Pillow** を利用し、探索は `quality` を中心にするニャン。
4. エンコードは基本 `method=6` 固定（時間と引き換えにサイズを詰める）ニャン。
5. αがあるPNGは、比較前に **固定背景へ合成**してから評価するニャン（例：背景 #000/#fff/#808080 のいずれかを選択可能にするニャン）。

---

## 推奨リポジトリ構成
- `.venv/`（python 仮想環境）
- `src/discord_webp_tuner/`
  - `cli.py`（Typer推奨、なければargparseでもOK）
  - `pipeline.py`（探索の主処理）
  - `metrics.py`（MS-SSIM/GMSD/PSNR等）
  - `io.py`（入出力、キャッシュ）
  - `plot.py`（散布図、Pareto、膝点検出）
  - `config.py`（探索レンジ・解像度・背景等）
- `scripts/`
  - `run_sweep.ps1` / `run_sweep.sh`（バッチ用）
- `data/`（ローカル専用、gitignore）
  - `input_png/`
  - `out_webp/`
  - `results/`
- `tests/`（最小でOK）
- `pyproject.toml`

---

## セットアップ

### 必須ツール
- Pythonの **Pillow が WebP をサポートしていること**ニャン。
  - 確認例：`from PIL import features; features.check("webp")` が `True` になることニャン。
  - Windowsのホイールで通常はOKだけど、環境によってはWebPが無効の場合があるので注意ニャン。

### Python依存（例）
- Pillow
- numpy
- torch（CPUでOK、あるならCUDA可）
- piq（MS-SSIM/GMSD用）
- pandas（集計）
- matplotlib（散布図）
- tqdm（進捗）
- typer（CLI、任意）

---

## 入出力仕様

### 入力
- PNG（sRGB想定）ニャン。
- 画像サイズは混在してよいが、評価は targetA に揃えるニャン。

### 出力
- `results/metrics.csv`（またはparquet）ニャン。
  - 必須カラム例：
    - `path_png`
    - `w`, `h`
    - `target`（A固定）
    - `q`（quality）
    - `method`（固定6）
    - `webp_bytes`
    - `bpp`（webp_bytes / (target_w*target_h)）
    - `ms_ssim_y`
    - `gmsd`
    - `psnr_y`（任意）
- `results/scatter_targetA.png`（散布図）ニャン。
- `out_webp/` に軽量WebPを保存（必要ならベストのみ）ニャン。

---

## パイプライン詳細

### 1) 前処理
- PNGを読み込み（Pillow）→必要ならRGB化ニャン。
- RGBAの場合：
  - 背景色を `bg_color` で選び合成しRGB化ニャン。
- 縮小：
  - targetAは **1280x720 (HD) の枠**に収まるよう、アスペクト比を維持してリサイズするニャン（16:9素材なら 1280x720 になるニャン）。
  - リサンプラは `LANCZOS` を推奨し、全工程で固定して再現性を担保するニャン。

### 2) WebPエンコード（Pillow）
- 方針：縮小後の画像を `Image.save(..., format="WEBP")` でエンコードするニャン。
- 代表パラメータ：
  - `quality={q}`（探索対象、0..100）
  - `method=6`（固定）
  - `use_sharp_yuv` をON/OFFして比較できる設計にするニャン（輪郭の色にじみ改善に効く場合があるニャン）。
- 実装イメージ（例）：
  - `img.save(out_path, "WEBP", quality=q, method=6, use_sharp_yuv=sharp_yuv)`
- 探索レンジ（例）：
  - まず粗く：`q = 30..80 step 5`
  - 絞り込み：膝付近を `step 1` で再探索ニャン。

### 3) デコード
- PillowでWebPを読み、RGBへ変換ニャン。
- 色管理の厳密さより「同じ手順で一貫」させることを優先するニャン。

### 4) 指標計算（targetごと）
- `orig_small`（縮小後の基準）と `webp_small`（デコード後）を比較するニャン。
- 推奨：
  - `MS-SSIM` は Y（輝度）で計算ニャン。
    - 簡易で良いので `YCbCr` に変換して Y を取り出す方針で統一するニャン。
  - `GMSD` は同じくYで計算するニャン。
- 値域・型：
  - torch tensorは `[N,C,H,W]`、float32、値域 `[0,1]` に正規化ニャン。

### 5) 可視化と意思決定

#### 5-1) 散布図（俯瞰）
- 横軸：`bpp` ニャン。
- 縦軸：`1 - ms_ssim_y`（小さいほど良い）ニャン。
- 色：`q` ニャン。
- Paretoフロント抽出（任意）：
  - “サイズが小さくて画質も良い”点を抽出して可視化ニャン。

#### 5-2) “飽和域の下端”を選ぶ（推奨）
狙い：**画質が飽和している範囲内で最も低い `q`** を選び、Discord上での破綻を抑えつつサイズを詰めるニャン。

- 前提：CSVは `per-image × q` が揃っているので、`q` ごとに集約して評価するニャン。
- 見る統計（例）：
  - `p10(ms_ssim_y)`（低いほど危険、ワースト寄りの安全性）
  - `p90(gmsd)`（高いほど危険、ワースト寄りの安全性）
  - 併用で `median(bpp)`（サイズの代表値）
- “飽和”の判定に使う増分（Δ）の例：
  - `Δ(p10(ms_ssim_y))`（`q` を上げた時の改善量）
  - `Δ(p90(gmsd))`（`q` を上げた時の改善量）
  - 追加で `Δmedian(bpp)`（サイズ増分）も見ると費用対効果が分かるニャン。
- 選び方（機械的に決める手順の例）：
  1. targetごとに `q` を昇順で並べ、上の統計とΔをプロットするニャン。
  2. ある `q` 以降で品質側のΔがほぼ0（改善が頭打ち）になったら、その区間を“飽和域”とみなすニャン。
  3. “飽和域”に入った最初の `q`（最小 `q`）を候補にするニャン。
  4. 最終確認として、その候補 `q` 付近のワースト画像を目視するニャン（アニメは同点でも見た目差が出ることがあるニャン）。

#### 5-3) 膝点（任意）
- 近似曲線＋曲率最大、またはkneedle的手法で候補を出すニャン。
- ただし `ms_ssim_y` が飽和しやすいので、最終採用は「飽和域の下端」＋目視を優先するニャン。

---

## パフォーマンス設計
- 画像枚数が多い前提なので、以下を入れるニャン：
  - キャッシュ（同一PNG×targetの縮小結果を保存して使い回す）ニャン。
  - WebP生成物も `q` ごとにキャッシュし、指標計算だけを再実行可能にするニャン。
  - 並列化：
    - 画像単位で `ProcessPoolExecutor` を検討ニャン。
    - torch/PIQはプロセスごと初期化コストがあるので、粒度は「画像1枚×q全探索」を1タスクにするのが無難ニャン。

---

## 目視サンプルの選び方（運用）
- 全画像を評価しても良いが、まずは代表サンプルを選びやすくするニャン：
  - 輪郭が多いカット（髪・瞳・服の皺）ニャン。
  - ベタ面が広いカット（空・壁・単色背景）ニャン。
  - 暗部があるカット（バンディングが出やすい）ニャン。
- 代表で候補 `q` を決めたら、全体に適用して “外れ値” だけ追加で調整するニャン。

---

## CLI要件（最低限）
- `sweep`：
  - 入力ディレクトリ、出力ディレクトリ
  - 例：targetAをHD想定に寄せるなら `--target-long-edge A=1280`（実装が長辺指定の場合）ニャン
  - `--q-min/--q-max/--q-step`
  - `--bg-color`（RGBA用）
  - `--sharp-yuv`（Pillowの `use_sharp_yuv` 切替）
  - `--save-webp`（全保存/ベストのみ/保存なし）
- `plot`：
  - CSVから散布図生成
  - targetは `A` のみ想定
  - Paretoフロントと膝点候補を描画（任意）
  - “飽和域の下端”用に `q`-vs-quantile と Δ のプロットを追加（推奨）

---

## テスト（最小でOK）
- 1枚のPNGを使い、同一入力に対して：
  - 縮小サイズが期待通り
  - 指標が範囲内（MS-SSIMは0..1、GMSDは>=0）
  - PillowのWebPサポートが無い場合に分かりやすく失敗する
  - RGBA合成が再現できる（背景固定）

---

## コーディング規約
- 例外メッセージは「どのファイルで何が起きたか」を必ず入れるニャン。
- パラメータ探索の再現性のため、リサイズ方式・色変換手順・背景合成手順は固定し、設定は全部ログ/CSVに書くニャン。
- 1回の実験結果は「CSV＋図＋設定（json）」で残せるようにするニャン。

---

## 完了条件（Definition of Done）
- 指定したPNG群に対し、targetA（必須）で `q` スイープを回し、散布図とCSVが出るニャン。
- `q` ごとの `p10(ms_ssim_y)` / `p90(gmsd)` とその Δ をプロットでき、飽和域の下端の候補 `q` を機械的に出せるニャン。
- 複数画像での候補 `q` が目視でも納得でき、Discord用の推奨設定として固定できるニャン。
